var documenterSearchIndex = {"docs":
[{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Broadcast,-and-reduce-arrays-example","page":"Examples","title":"Broadcast, and reduce arrays example","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"addprocs(7)\n@everywhere using DistributedOperations\n\nx = ones(10)\n\n# broadcast x to all pids\n_x = bcast(x) # equivalent to bcast(x, procs())\n\n# manipulate x on one of the workers\n@everywhere myop!(future) = begin fetch(future)::Vector{Float64} .= 2.0; nothing end\nremotecall_fetch(myop!, workers()[1], _x[workers()[1]])\n\n# parallel reduction\ny = reduce!(futures)\n@show y\n\nrmprocs(workers())","category":"page"},{"location":"examples/#Reduce-arrays-example","page":"Examples","title":"Reduce arrays example","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Here, we construct","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"addprocs(7)\n@everywhere using DistributedOperations\n\n# construct arrays of the same size on each process\nfutures = ArrayFutures(Float64, (10,))\n\n# fill with values\n@everywhere myfill!(future) = begin fetch(future) .= π; nothing end\n@sync for pid in procs()\n    @async remotecall_fetch(myfill!, pid, futures[pid])\nend\n\n# parallel reduction\ny = reduce!(futures)\n\nrmprocs(workers())","category":"page"},{"location":"examples/#Broadcast-and-reduce-applied-to-a-composite-struct","page":"Examples","title":"Broadcast and reduce applied to a composite struct","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"For generic types, we provide custom reduction and copy methods.  For example,","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"addprocs(7)\n@everywhere using DistributedOperations\n\n@everywhere struct B\n    x::Vector{Float64}\n    y::Vector{Float64}\nend\n\nx = B(ones(10),2*ones(10))\nfutures = bcast(x)\n\n@everywhere function reducemethod!(b,a)\n    b.x .+= a.x\n    b.y .+= b.y\nend\n\ny = reduce!(futures, reducemethod!)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Continuing from the previous example, we illustrate how to make a copy of a TypeFuture when using a composite structure.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"@everywhere function copymethod!(b,a)\n    b.x .= a.x\n    b.y .= a.y\nend\n\nfutures_copy = TypeFutures(B, ()->B(zeros(10), zeros(10)))\ncopy!(futures_copy, futures, copymethod!)","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [DistributedOperations]\nOrder   = [:function, :type]","category":"page"},{"location":"reference/#Base.copy!-Union{Tuple{T}, Tuple{TypeFutures{T},TypeFutures{T},Function}, Tuple{TypeFutures{T},TypeFutures{T},Function,AbstractArray}} where T","page":"Reference","title":"Base.copy!","text":"copy!(to::TypeFutures, from::TypeFutures[, copymethod!=DistributedOperations.paralleloperations_copy!, pids])\n\nCopy from into to using copymethod!.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Base.fill!-Union{Tuple{T}, Tuple{TypeFutures{T},Number,Function}, Tuple{TypeFutures{T},Number,Function,AbstractArray}} where T","page":"Reference","title":"Base.fill!","text":"fill!(x::TypeFutures, a[, fillmethod!=DistributedOperations.fillmethod!, pids])\n\nFill x with a::Number using the fillmethod!::Function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedArrays.localpart-Union{Tuple{TypeFutures{T}}, Tuple{T}} where T","page":"Reference","title":"DistributedArrays.localpart","text":"localpart(x::TypeFutures)\n\nGet the piece of x::TypeFutures that is local to myid().\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.bcast!-Union{Tuple{T}, Tuple{TypeFutures{T},Any}} where T","page":"Reference","title":"DistributedOperations.bcast!","text":"bcast!(x::TypeFutures, pids)\n\nBroadcast an existing x::TypeFutures to pids.  This is useful for elastic computing where the cluster may grow after the construction and broadcast of x::TypeFuture.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.bcast-Union{Tuple{T}, Tuple{T}, Tuple{T,Any}} where T","page":"Reference","title":"DistributedOperations.bcast","text":"bcast(x[, pids=procs()])\n\nBroadcast x to pids.\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using DistributedOperations\nx = rand(10)\n_x = bcast(x)\ny = remotecall_fetch(localpart, workers()[1], _x)\ny ≈ x  # true\nrmprocs(workers())\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.reduce!-Union{Tuple{TypeFutures{T}}, Tuple{T}, Tuple{TypeFutures{T},Function}} where T","page":"Reference","title":"DistributedOperations.reduce!","text":"y = reduce!(x::TypeFutures[, reducemethod!=DistributedOperations.paralleloperations_reduce!])\n\nParallel reduction of x::TypeFutures using reducemethod!.  By default, the reduction is a mutating in-place element-wise addition, such that y=localpart(x).\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using DistributedOperations\nx = ArrayFutures(Float64, (3,))\nfill!(x, 1, workers())\ny = reduce!(x)\ny ≈ [2.0,2.0,2.0] # true\nlocalpart(x) ≈ [2.0,2.0,2.0] # true\nrmprocs(workers())\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.ArrayFutures-Union{Tuple{Array{T,N}}, Tuple{N}, Tuple{T}, Tuple{Array{T,N},Any}} where N where T","page":"Reference","title":"DistributedOperations.ArrayFutures","text":"x = ArrayFutures(x::Array[, pids=procs()])\n\nCreate x::TypeFutures, and where myid() is assigned x, and all other processes are assigned zeros(eltype(x), size(x)).\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.ArrayFutures-Union{Tuple{I}, Tuple{N}, Tuple{T}, Tuple{Type{T},Tuple{Vararg{I,N}}}, Tuple{Type{T},Tuple{Vararg{I,N}},Any}} where I<:Integer where N where T","page":"Reference","title":"DistributedOperations.ArrayFutures","text":"x = ArrayFutures(T, n::NTuple{N,Int}[, pids=procs()])\n\nCreate x::TypeFutures, and where each proccess id (pid) in pids is assigned zeros(T,n).\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using DistributedOperations\nx = ArrayFutures(Float32, (10,20), procs())\nlocalpart(x)\nrmprocs(workers())\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.TypeFutures-Union{Tuple{T}, Tuple{T,Function,AbstractArray,Vararg{Any,N} where N}} where T","page":"Reference","title":"DistributedOperations.TypeFutures","text":"x = TypeFutures(y::T, f[, pids=procs()], fargs...)\n\nConstrut a x::TypeFutures from y::T on workers defined by the process id's pids.  On each worker pid, f is evaluated, and a future for what is returned by f is stored.\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using DistributedOperations\n@everywhere struct MyStruct\n    x::Vector{Float64}\n    y::Vector{Float64}\nend\n@everywhere foo() = MyStruct(rand(10), rand(10))\nx = foo()\nx = TypeFutures(x, foo, procs())\n@show remotecall_fetch(localpart, workers()[1], x)\nrmprocs(workers())\n\n\n\n\n\n","category":"method"},{"location":"reference/#DistributedOperations.TypeFutures-Union{Tuple{T}, Tuple{Type{T},Function,AbstractArray,Vararg{Any,N} where N}} where T","page":"Reference","title":"DistributedOperations.TypeFutures","text":"x = TypeFutures(T, f, pids, fargs...)\n\nConstrut a x::TypeFutures of type T on workers defined by the process id's pids.  On each worker pid, f is evaluated, and a future for what is returned by f is stored.\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using DistributedOperations\n@everywhere struct MyStruct\n    x::Vector{Float64}\n    y::Vector{Float64}\nend\n@everywhere foo() = MyStruct(rand(10), rand(10))\nx = TypeFutures(MyStruct, foo, procs())\n@show remotecall_fetch(localpart, workers()[1], x)\nrmprocs(workers())\n\n\n\n\n\n","category":"method"},{"location":"#DistributedOperations.jl","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"","category":"section"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"Fast parallel broadcast and reduction operations for Julia using binary-tree algorithms.  Note that we can broadcast and reduce over any Julia type, but we provide convenience methods for performing these operations on Julia arrays.","category":"page"},{"location":"#Broadcast","page":"DistributedOperations.jl","title":"Broadcast","text":"","category":"section"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"The bcast method copies an object to a set of machines.  The object can be either an array or a composite structure.  The broadcasted object is stored as an Dict{Int,Future} using the TypeFutures struct.  We retrieve the local part of the TypeFuture using the fetch method.","category":"page"},{"location":"#Reduce","page":"DistributedOperations.jl","title":"Reduce","text":"","category":"section"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"The reduce! method, reduces a TypeFuture across all participating workers.  The reduction follows the reducemethod! which is an optional argument to reduce!. By default the reduction is a element-wise addition (i.e. .+=).  This is appropriate for our most common use case where each item in TypeFuture is an array of a common size and type.  In this case the resulting reduction is another array of that same common size and type.","category":"page"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"Please note that reduce! mutates the TypeFuture that it is applied to.  Hence, calling reduce! twice on the same TypeFuture will produce different results.","category":"page"},{"location":"#Similar-packages","page":"DistributedOperations.jl","title":"Similar packages","text":"","category":"section"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"There are other packages that provide similar (but not equivalent) functionality, and it may be worth thinking about how to consolidate efforts in the future:","category":"page"},{"location":"","page":"DistributedOperations.jl","title":"DistributedOperations.jl","text":"ParallelOperations.jl - https://github.com/JuliaAstroSim/ParallelOperations.jl\nParallelDataTransfer.jl - https://github.com/ChrisRackauckas/ParallelDataTransfer.jl\nArrayChannels.jl - https://github.com/rohanmclure/ArrayChannels.jl","category":"page"}]
}
